## Machine Learning 2026-1

You can find the course syllabus in th file: *Aprendizaje de MÃ¡quina.pdf*

### Course prerequisites (Linear Algebra, Probability and Statistics and Differential Calculus).
- Basic Information Theory tools (entropy, information, mutual information, KL-Diveregence).
- Algebraic structures (groups, rings, fields, vector spaces, modules)
- Metric spaces, normed spaces, inner-product spaces, Hilbert spaces.
- Orthogonal projection theorem.
- Mercer Theorem.
- Partial detivates (definition, chain rule for partial derivatives).
- Gradient and  Hessian.
- Gradient descent algoritms.
- Tensors (tensor product theorem).
  
### 1. Learning
#### Supervised Learning (Statistical Learning Theory)
- Training and testing (theory of generalization, generalization bound, generalization tradeoff, bias-variance tradeoff, and learning curves).
- Linear model (linear regression, logistic regression).
- Overfitting (regularization and validation techniques).
- Learning principles (Ocam's Razor, sampling bias, data snooping).
- Modern Statistical Learning Theory insights.
#### Unsupervised Learning 
- Definition and examples.
#### Selfsupervised Learning
- Definition and examples.
### 3. Basic Machine Learning Algorithms 
#### Classificcation
- Linear Discriminant Analysis
- Naive Bayes.
- Nearest-neighbors.
- Decision Trees.
- Bagging.
- Boosting.
- Random Forest.
- Gradient Boosting Machines.
- Support Vector Machines.
- Multilayer perceptron (backpropagation).
- Stacking techniques.
#### Regression
- Nearest-neighbors.
- Random Forest.
- Support Vector.
- Multilayer perceptron.
- Gaussian Process.
#### Clustering
- k-Means.
- Hierarchical Clustering.
- DBSCAN
- Gaussian Mixture Models.
#### Dimensionality Reduction
- Principal Component Analysis.
- t-SNE.
- UMAP.
#### Selected Topics
- Tensor Decompositions


