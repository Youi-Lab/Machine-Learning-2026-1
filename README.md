## Machine Learning 2026-1

### Requires: Probability and Statistics.

### 1. Math Review
- Basic Information Theory tools (entropy, information, mutual entropy, KL-Diveregence).
- Algebraic structures (groups, rings, fields, vector spaces, modules)
- Metric spaces, normed spaces, inner-product spaces, Hilbert spaces.
- Orthogonal projection theorem.
- Mercer Theorem.
- Partial detivates (chain rule for partial derivatives).
- Gradient and  Hessian matrix.
- Gradient descent algoritm.
- Tensors (tensor product theorem). 
### 2. Learning
#### Supervised Learning (Statistical Learning Theory)
- Training and testing (theory of generalization, generalization bound, generalization tradeoff, bias-variance tradeoff, and learning curves).
- Linear model (linear regression, logistic regression).
- Overfitting (regularization and validation techniques).
- Learning principles (Ocam's Razor, sampling bias, data snooping).
#### Unsupervised Learning 
- Definition and examples.
#### Selfsupervised Learning
- Definition and examples.
### 3. Basic Machine Learning Algorithms 
#### Classificcation
- Naive Bayes.
- Nearest-neighbors.
- Decision Trees.
- Bagging.
- Boosting.
- Random Forest.
- Gradient Boosting Machines.
- Support Vector Machines.
- Multilayer perceptron (backpropagation).
- Stacking techniques.
#### Regression
- Nearest-neighbors.
- Random Forest.
- Support Vector.
- Multilayer perceptron.
- Gaussian Process.
#### Clustering
- k-Means.
- Hierarchical Clustering.
- DBSCAN
- Gaussian Mixture Models.
#### Dimensionality Reduction
- Principal Component Analysis.
- t-SNE.
- UMAP.
#### Selected Topics
- Tensor Decompositions


